{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Attacked_Model/BATADAL/autoencoder.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alessando/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.preprocessing.data module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/alessando/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.19.1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from Attacked_Model.autoencoder_BATADAL import load_AEED\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_curve, auc, precision_score, recall_score\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "att_data = pd.read_csv('../Data/BATADAL/attack_10_from_test_dataset.csv')\n",
    "\n",
    "# define the column sets for the pandas dataframes\n",
    "xset = [col for col in att_data.columns if col not in ['Unnamed: 0', 'DATETIME', 'ATT_FLAG']]\n",
    "yset = ['ATT_FLAG']\n",
    "\n",
    "autoencoder = load_AEED(\"../Attacked_Model/BATADAL/autoencoder.json\", \"../Attacked_Model/BATADAL/autoencoder.h5\")\n",
    "scaler = pickle.load(open(\"../Attacked_Model/BATADAL/scaler.p\", \"rb\"))\n",
    "with open(\"../Attacked_Model/BATADAL/theta\") as f:\n",
    "        theta = float(f.read())\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores(Y, Yhat):\n",
    "    return [accuracy_score(Y, Yhat), f1_score(Y, Yhat), precision_score(Y, Yhat), recall_score(Y, Yhat)]#, fpr[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Constrained attack over X dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "25",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c9469d979993>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mresults_black\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_concealeble_variables\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'black'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mresults_mean_white\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_concealeble_variables\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_mean_white\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_concealeble_variables\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresults_white\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_concealeble_variables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mresults_mean_black\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_concealeble_variables\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_mean_black\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_concealeble_variables\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresults_black\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_concealeble_variables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 25"
     ]
    }
   ],
   "source": [
    "results_mean_replay = {new_list: 0 for new_list in [2,3,4,5,6,7,8,9,10,15,20, 43]}\n",
    "results_mean_white = {new_list: 0 for new_list in [2,3,4,5,6,7,8,9,10,15,20, 43]}\n",
    "results_mean_black = {new_list: 0 for new_list in [2,3,4,5,6,7,8,9,10,15,20, 43]}\n",
    "sum_orig = 0\n",
    "\n",
    "for i in range(1,15):\n",
    "    df_test_01 = pd.read_csv('../Data/BATADAL/attack_'+str(i)+'_from_test_dataset.csv', parse_dates = ['DATETIME'], dayfirst=True)\n",
    "    X3 = pd.DataFrame(index=df_test_01.index, columns=xset,\n",
    "                      data=scaler.transform(df_test_01[xset]))    \n",
    "    Y3 = [1]*len(X3)\n",
    "    Yhat3, _, _, _ = autoencoder.detect(X3, theta=theta, window=3, average=True)\n",
    "    results_orig = pd.DataFrame(\n",
    "                           columns=['accuracy', 'f1_score', 'precision', 'recall'])#,'fpr'])\n",
    "    results_orig.loc['orig'] = compute_scores(Y3, Yhat3)\n",
    "    sum_orig = sum_orig + results_orig.loc['orig'].at['accuracy']\n",
    "    results_replay = {}\n",
    "    results_white = {}\n",
    "    results_black = {}\n",
    "    for max_concealeble_variables in [2,3,4,5,6,7,8,9,10,15,20,25,30,35,40,43]:\n",
    "            \n",
    "            if not(max_concealeble_variables == 43):\n",
    "                white_box = pd.read_csv('../Adversarial_Attacks/Whitebox_Attack/results/BATADAL/max_constraints_fixed/whitebox_attack_'+str(i)+\n",
    "                                        '_from_test_dataset_max_'+str(max_concealeble_variables)+'.csv', dayfirst=True)\n",
    "                black_box = pd.read_csv('../Adversarial_Attacks/Black_Box_Attack/results/BATADAL/AE_max_concealable_var_'+\n",
    "                                        str(max_concealeble_variables)+\n",
    "                                        '/new_advAE_attack_'+str(i)+'_from_test_dataset_max'+str(max_concealeble_variables)+'.csv', dayfirst=True)\n",
    "            else:\n",
    "                white_box = pd.read_csv('../Adversarial_Attacks/Whitebox_Attack/results/BATADAL/new_improved_whitebox_attack_'+str(i)+'_from_test_dataset.csv', dayfirst=True)\n",
    "                black_box = pd.read_csv('../Adversarial_Attacks/Black_Box_Attack/results/BATADAL/unconstrained_attack/new_advAE_attack_'+str(i)+'_from_test_dataset.csv', dayfirst=True)\n",
    "            \n",
    "            white_box = pd.DataFrame(index=white_box.index, columns=xset,\n",
    "                      data=scaler.transform(white_box[xset]))\n",
    "            black_box = pd.DataFrame(index=black_box.index, columns=xset,\n",
    "                      data=scaler.transform(black_box[xset]))\n",
    "            \n",
    "            Y5 = [1]*len(white_box)\n",
    "            Y6 = [1]*len(black_box)\n",
    "            \n",
    "            Yhat5, _, _, _ = autoencoder.detect(white_box, theta=theta, window=3, average=True)\n",
    "            Yhat6, _, _, _ = autoencoder.detect(black_box, theta=theta, window=3, average=True)\n",
    "            \n",
    "            results = pd.DataFrame(\n",
    "                           columns=['accuracy', 'f1_score', 'precision', 'recall'])#,'fpr'])\n",
    "            results.loc['white'] = compute_scores(Y5, Yhat5)\n",
    "            results.loc['black'] = compute_scores(Y6, Yhat6)\n",
    "            \n",
    "            results_white[max_concealeble_variables] = results.loc['white'].at['accuracy']\n",
    "            results_black[max_concealeble_variables] = results.loc['black'].at['accuracy']  \n",
    "            \n",
    "            results_mean_white[max_concealeble_variables] = results_mean_white[max_concealeble_variables] + results_white[max_concealeble_variables]\n",
    "            results_mean_black[max_concealeble_variables] = results_mean_black[max_concealeble_variables] + results_black[max_concealeble_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "35",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-23cdd653c5d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresults_attack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m43\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m35\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m43\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m35\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mresults_attack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'white'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_mean_white\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mresults_attack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'black'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_mean_black\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 35"
     ]
    }
   ],
   "source": [
    "results_attack = pd.DataFrame(columns=[43, 35,30,25, 20, 15, 10, 9, 8, 7, 6, 5, 4, 3, 2])\n",
    "for j in [43, 35, 30, 25,  20, 15, 10, 9, 8, 7, 6, 5, 4, 3, 2]:\n",
    "    results_attack.loc['white', j] = round(results_mean_white[j]/14, 2)\n",
    "    results_attack.loc['black', j] = round(results_mean_black[j]/14, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Accuracy: \"+str(round(sum_orig/14,2)))\n",
    "print(\"Accuracy After Constrained Variables Adversarial Attack\")\n",
    "results_attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Constrained Attack over D dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_mean_percentage_reduced = {new_list: [] for new_list in [5, 10, 25, 50, 75]}#['5%', '10%', '25%', '50%', '75%']}\n",
    "results_percentage_reduced = {}\n",
    "accuracy = {}\n",
    "for percentage in [5, 10, 25, 50, 75]:\n",
    "    accuracy[percentage] = {}\n",
    "    for seed in [0, 1, 12, 123, 1234, 12345, 123456, 1234567, 12345678, 123456789]:\n",
    "        for i in range(1,15):\n",
    "            dataset = pd.read_csv('../Adversarial_Attacks/Black_Box_Attack/results/BATADAL/AE_'+str(percentage)\n",
    "                                    +'_percent/seed_'+str(seed)+'/new_advAE_attack_'+str(i)+'_from_test_dataset.csv'\n",
    "                                    , dayfirst=True)\n",
    "            dataset = pd.DataFrame(index=dataset.index, columns=xset,\n",
    "                      data=scaler.transform(dataset[xset]))\n",
    "            Y7  = [1]*len(dataset)\n",
    "            Yhat7, _, _, _ = autoencoder.detect(dataset, theta=theta, window=3, average=True)\n",
    "            \n",
    "            results = pd.DataFrame(\n",
    "                           columns=['accuracy', 'f1_score', 'precision', 'recall'])\n",
    "            results.loc['percentage'] = compute_scores(Y7, Yhat7) \n",
    "            \n",
    "            #mean.append()\n",
    "            \n",
    "            try:\n",
    "                  accuracy[percentage]['att_'+str(i)].append(results.loc['percentage'].at['accuracy'])                              \n",
    "            except:\n",
    "                accuracy[percentage]['att_'+str(i)] = []\n",
    "                accuracy[percentage]['att_'+str(i)].append(results.loc['percentage'].at['accuracy'])\n",
    "    mean=[]\n",
    "    std = []\n",
    "    for i in range(1,15):\n",
    "        mean.append(np.mean(accuracy[percentage]['att_'+str(i)]))\n",
    "        std.append(np.std(accuracy[percentage]['att_'+str(i)]))\n",
    "    \n",
    "    results_mean_percentage_reduced[percentage].append(np.mean(mean))\n",
    "    results_mean_percentage_reduced[percentage].append(np.mean(std))\n",
    "\n",
    "results_mean_percentage_reduced=pd.DataFrame.from_dict(results_mean_percentage_reduced, orient='index', columns = ['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy after Constrained Attack over D Dimension\")\n",
    "results_mean_percentage_reduced.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
