{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Attacked_Model/WADI/autoencoder.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alessando/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.preprocessing.data module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/alessando/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.19.1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from util import fill_window\n",
    "from Attacked_Model.autoencoder_BATADAL import load_AEED\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_curve, auc, precision_score, recall_score\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "#select wich dataset are you considering\n",
    "#we are not allowed to publish WADI data, please request them itrust Singapore website\n",
    "dataset = 'WADI' #'WADI'\n",
    "data_folder = '../Data/'+dataset\n",
    "att_data = pd.read_csv(data_folder+'/attack_1_from_test_dataset.csv')\n",
    "xset = [col for col in att_data.columns if col not in [\n",
    "        'Row', 'DATETIME','ATT_FLAG', '2_MV_001_STATUS', '2_LT_001_PV', '2_MV_002_STATUS']]\n",
    "\n",
    "yset = ['ATT_FLAG']\n",
    "autoencoder = load_AEED(\"../Attacked_Model/\"+dataset+\"/autoencoder.json\", \"../Attacked_Model/\"+dataset+\"/autoencoder.h5\")\n",
    "scaler = pickle.load(open(\"../Attacked_Model/\"+dataset+\"/scaler.p\", \"rb\"))\n",
    "with open(\"../Attacked_Model/\"+dataset+\"/theta\") as f:\n",
    "        theta = float(f.read())\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores(Y, Yhat):\n",
    "    Y = Y.drop(Y.index[0:60])\n",
    "    Yhat = Yhat.drop(Yhat.index[0:60])\n",
    "    return [accuracy_score(Y, Yhat), f1_score(Y, Yhat), precision_score(Y, Yhat), recall_score(Y, Yhat)]#, fpr[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Constrained attack over X dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ../Adversarial_Attacks/Whitebox_Attack/results/WADI/max_constraints_fixed/whitebox_attack_1_from_test_dataset_max_80.csv does not exist: '../Adversarial_Attacks/Whitebox_Attack/results/WADI/max_constraints_fixed/whitebox_attack_1_from_test_dataset_max_80.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ef59bc247682>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_concealeble_variables\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m82\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 white_box = pd.read_csv('../Adversarial_Attacks/Whitebox_Attack/results/'+dataset+'/max_constraints_fixed/whitebox_attack_'+str(i)+\n\u001b[0;32m---> 28\u001b[0;31m                                         '_from_test_dataset_max_'+str(max_concealeble_variables)+'.csv', dayfirst=True)\n\u001b[0m\u001b[1;32m     29\u001b[0m                 black_box = pd.read_csv('../Adversarial_Attacks/Black_Box_Attack/results/'+dataset+'/AE_max_concealable_var_'+\n\u001b[1;32m     30\u001b[0m                                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_concealeble_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File ../Adversarial_Attacks/Whitebox_Attack/results/WADI/max_constraints_fixed/whitebox_attack_1_from_test_dataset_max_80.csv does not exist: '../Adversarial_Attacks/Whitebox_Attack/results/WADI/max_constraints_fixed/whitebox_attack_1_from_test_dataset_max_80.csv'"
     ]
    }
   ],
   "source": [
    "results_mean_replay = {new_list: 0 for new_list in [2,3,4,5,6,7,8,9,10,15,20,30,40,50,60,70,80,82]}\n",
    "results_mean_white = {new_list: 0 for new_list in [2,3,4,5,6,7,8,9,10,15,20,30,40,50,60,70,80,82]}\n",
    "results_mean_black = {new_list: 0 for new_list in [2,3,4,5,6,7,8,9,10,15,20,30,40,50,60,70,80,82]}\n",
    "sum_orig = 0\n",
    "\n",
    "original_data = pd.read_csv('../Data/'+dataset+'/attacks_october_clean_with_label.csv', parse_dates = ['DATETIME'], dayfirst=True)\n",
    "original_data = original_data.set_index('DATETIME')\n",
    "\n",
    "for i in [1,2,3,5,6,7,8,9,10,11,12,13,14,15]:\n",
    "    df_test_01 = pd.read_csv('../Data/'+dataset+'/attack_'+str(i)+'_from_test_dataset.csv', parse_dates = ['DATETIME'], dayfirst=True)\n",
    "    df_test_01 = fill_window(original_data, df_test_01, i, 60)\n",
    "    X3 = pd.DataFrame(index=df_test_01.index, columns=xset,\n",
    "                      data=scaler.transform(df_test_01[xset])) \n",
    "    Y3 = df_test_01[yset]\n",
    "    Yhat3, _, _, _ = autoencoder.detect(X3, theta=theta, window=60, average=True)\n",
    "    results_orig = pd.DataFrame(\n",
    "                           columns=['accuracy', 'f1_score', 'precision', 'recall'])#,'fpr'])\n",
    "    results_orig.loc['orig'] = compute_scores(Y3, Yhat3)\n",
    "    sum_orig = sum_orig + results_orig.loc['orig'].at['accuracy']\n",
    "    results_replay = {}\n",
    "    results_white = {}\n",
    "    results_black = {}\n",
    "    for max_concealeble_variables in [2,3,4,5,6,7,8,9,10,15,20,30,40,50,60,70,80,82]:\n",
    "            replay = pd.read_csv('../Adversarial_Attacks/Replay_Attack/results/'+dataset+'/attack_'+str(i)+\n",
    "                                        '_replay_max_'+str(max_concealeble_variables)+'.csv', dayfirst=True)\n",
    "            if not(max_concealeble_variables == 82):\n",
    "                white_box = pd.read_csv('../Adversarial_Attacks/Whitebox_Attack/results/'+dataset+'/max_constraints_fixed/whitebox_attack_'+str(i)+\n",
    "                                        '_from_test_dataset_max_'+str(max_concealeble_variables)+'.csv', dayfirst=True)\n",
    "                black_box = pd.read_csv('../Adversarial_Attacks/Black_Box_Attack/results/'+dataset+'/AE_max_concealable_var_'+\n",
    "                                        str(max_concealeble_variables)+\n",
    "                                        '/new_advAE_attack_'+str(i)+'_from_test_dataset_max'+str(max_concealeble_variables)+'.csv', dayfirst=True)\n",
    "            else:\n",
    "                white_box = pd.read_csv('../Adversarial_Attacks/Whitebox_Attack/results/'+dataset+'/unconstrained_attack/new_improved_whitebox_attack_'+str(i)+'_from_test_dataset.csv', dayfirst=True)\n",
    "                black_box = pd.read_csv('../Adversarial_Attacks/Black_Box_Attack/results/'+dataset+'/unconstrained_attack/new_advAE_attack_'+str(i)+'_from_test_dataset.csv', dayfirst=True)\n",
    "                          \n",
    "            \n",
    "            replay = fill_window(original_data, replay, i, 60)\n",
    "            white_box = fill_window(original_data, white_box, i, 60)\n",
    "            black_box = fill_window(original_data, black_box, i, 60)\n",
    "            replay = pd.DataFrame(index=replay.index, columns=xset,\n",
    "                      data=scaler.transform(replay[xset]))\n",
    "            white_box = pd.DataFrame(index=white_box.index, columns=xset,\n",
    "                      data=scaler.transform(white_box[xset]))\n",
    "            black_box = pd.DataFrame(index=black_box.index, columns=xset,\n",
    "                      data=scaler.transform(black_box[xset]))\n",
    "\n",
    "            Y4 = Y3#[1]*len(replay)\n",
    "            Y5 = Y3#[1]*len(white_box)\n",
    "            Y6 = Y3#[1]*len(black_box)\n",
    "            \n",
    "            Yhat4, _, _, _ = autoencoder.detect(replay, theta=theta, window=60, average=True)\n",
    "            Yhat5, _, _, _ = autoencoder.detect(white_box, theta=theta, window=60, average=True)\n",
    "            Yhat6, _, _, _ = autoencoder.detect(black_box, theta=theta, window=60, average=True)\n",
    "            \n",
    "            results = pd.DataFrame(\n",
    "                           columns=['accuracy', 'f1_score', 'precision', 'recall'])#,'fpr'])\n",
    "            #results.loc['original'] = compute_scores(Y3, Yhat3)\n",
    "            results.loc['replay'] = compute_scores(Y4, Yhat4)\n",
    "            results.loc['white'] = compute_scores(Y5, Yhat5)\n",
    "            results.loc['black'] = compute_scores(Y6, Yhat6)\n",
    "            \n",
    "            \n",
    "            #print(i, max_concealeble_variables)\n",
    "            #print(results)\n",
    "            \n",
    "            results_replay[max_concealeble_variables] = results.loc['replay'].at['recall']\n",
    "            results_white[max_concealeble_variables] = results.loc['white'].at['recall']\n",
    "            results_black[max_concealeble_variables] = results.loc['black'].at['recall']  \n",
    "            \n",
    "            results_mean_replay[max_concealeble_variables] = results_mean_replay[max_concealeble_variables] + results_replay[max_concealeble_variables]\n",
    "            results_mean_white[max_concealeble_variables] = results_mean_white[max_concealeble_variables] + results_white[max_concealeble_variables]\n",
    "            results_mean_black[max_concealeble_variables] = results_mean_black[max_concealeble_variables] + results_black[max_concealeble_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_attack = pd.DataFrame(columns=[82,80,70,60,50,40,30,20,15,10,9,8,7,6,5,4,3,2])\n",
    "for j in [82,80,70,60,50,40,30,20,15,10,9,8,7,6,5,4,3,2]:\n",
    "    results_attack.loc['replay', j] = round(results_mean_replay[j]/14, 2)\n",
    "    results_attack.loc['white', j] = round(results_mean_white[j]/14, 2)\n",
    "    results_attack.loc['black', j] = round(results_mean_black[j]/14, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Recall: \"+str(round(sum_orig/14,2)))\n",
    "print(\"Recall After Constrained Variables Adversarial Attack\")\n",
    "results_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "legend = ['replay', 'iterative', 'learning']\n",
    "plt.tight_layout()\n",
    "fig, ax = plt.subplots(figsize=(6,2))\n",
    "ax.hlines(y=round(sum_orig/14,2),xmin=0, xmax=82, color='r', linestyles='--',)\n",
    "ax.plot(results_attack.transpose(), 'o-',bbox_to_anchor=(0., 1.02, 1., .102), loc='lower left',\n",
    "           ncol=4, mode=\"expand\", borderaxespad=0.)\n",
    "plt.xticks(np.arange(0, 82, 10))\n",
    "plt.ylim(-0.11,1.0)\n",
    "plt.legend(np.append(legend, 'original'))\n",
    "plt.title('Recall score after constrained attack')\n",
    "plt.xlabel('# Controlled sensors k')\n",
    "plt.ylabel('Recall')\n",
    "plt.savefig('plot_recall_WADI.pdf', bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Constrained Attack over D dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_mean_percentage_reduced = {new_list: [] for new_list in [5, 10, 25, 50, 75]}#['5%', '10%', '25%', '50%', '75%']}\n",
    "results_percentage_reduced = {}\n",
    "accuracy = {}\n",
    "for percentage in [5, 10, 25, 50, 75]:\n",
    "    accuracy[percentage] = {}\n",
    "    for seed in [0, 1, 12, 123, 1234, 12345, 123456, 1234567, 12345678, 123456789]:\n",
    "        for i in [1,2,3,5,6,7,8,9,10,11,12,13,14,15]:\n",
    "\n",
    "            dataset = pd.read_csv('../Adversarial_Attacks/Black_Box_Attack/results/WADI/AE_'+str(percentage)\n",
    "                                    +'_percent/seed_'+str(seed)+'/new_advAE_attack_'+str(i)+'_from_test_dataset.csv'\n",
    "                                    , dayfirst=True)\n",
    "            dataset = fill_window(original_data, dataset, i, 60)\n",
    "            \n",
    "            dataset = pd.DataFrame(index=dataset.index, columns=xset,\n",
    "                      data=scaler.transform(dataset[xset]))\n",
    "            Y7  = pd.DataFrame([1]*len(dataset))\n",
    "            Yhat7, _, _, _ = autoencoder.detect(dataset, theta=theta, window=3, average=True)\n",
    "            \n",
    "            results = pd.DataFrame(\n",
    "                           columns=['accuracy', 'f1_score', 'precision', 'recall'])\n",
    "            results.loc['percentage'] = compute_scores(Y7, Yhat7) \n",
    "            \n",
    "            try:\n",
    "                  accuracy[percentage]['att_'+str(i)].append(results.loc['percentage'].at['accuracy'])                              \n",
    "            except:\n",
    "                accuracy[percentage]['att_'+str(i)] = []\n",
    "                accuracy[percentage]['att_'+str(i)].append(results.loc['percentage'].at['accuracy'])\n",
    "    mean=[]\n",
    "    std = []\n",
    "    for i in [1,2,3,5,6,7,8,9,10,11,12,13,14,15]:\n",
    "        mean.append(np.mean(accuracy[percentage]['att_'+str(i)]))\n",
    "        std.append(np.std(accuracy[percentage]['att_'+str(i)]))\n",
    "    \n",
    "    results_mean_percentage_reduced[percentage].append(np.mean(mean))\n",
    "    results_mean_percentage_reduced[percentage].append(np.mean(std))\n",
    "\n",
    "results_mean_percentage_reduced=pd.DataFrame.from_dict(results_mean_percentage_reduced, orient='index', columns = ['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy after Constrained Attack over D Dimension\")\n",
    "results_mean_percentage_reduced.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
